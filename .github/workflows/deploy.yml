name: Deploy to GitHub Pages

on:
  push:
    branches:
      - main
    # Review gh actions docs if you want to further define triggers, paths, etc
    # https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#on

jobs:
  build:
    name: Build Docusaurus
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0
      - uses: actions/setup-node@v4
        with:
          node-version: 24
          cache: npm

      - name: Install dependencies
        run: npm ci
      - name: Build website
        env:
          MEILISEARCH_HOST: ${{ secrets.MEILISEARCH_HOST }}
          MEILISEARCH_SEARCH_KEY: ${{ secrets.MEILISEARCH_SEARCH_KEY }}
        run: npm run build

      - name: Run scraper
        env:
          MEILISEARCH_HOST_URL: ${{ secrets.MEILISEARCH_HOST }}
          MEILISEARCH_API_KEY: ${{ secrets.MEILISEARCH_ADMIN_KEY }}
        run: |
          # 1. 在背景啟動伺服器
          npx -y serve build -l 3000 &
          SERVE_PID=$!

          # 2. 等待伺服器啟動 (最多等 30 秒)
          echo "Waiting for local server to be ready..."
          for i in {1..30}; do
            if curl -s http://localhost:3000 > /dev/null; then
              echo "Server is up!"
              break
            fi
            sleep 1
          done

          # 3. 準備臨時 sitemap (將正式網址替換為 localhost)
          cp build/sitemap.xml build/sitemap-local.xml
          sed -i 's|https://material.nics.nat.gov.tw|http://localhost:3000|g' build/sitemap-local.xml

          # 4. 準備臨時 scraper 設定
          # 使用 url_mirror 讓 Scraper 爬取 localhost 但索引正式網址
          cp scraper.json scraper-local.json
          sed -i 's|https://material.nics.nat.gov.tw/sitemap.xml|http://localhost:3000/sitemap-local.xml|g' scraper-local.json

          # 5. 執行 Scraper
          docker run -t --rm \
            --network="host" \
            -e MEILISEARCH_HOST_URL=$MEILISEARCH_HOST_URL \
            -e MEILISEARCH_API_KEY=$MEILISEARCH_API_KEY \
            -v $PWD/scraper-local.json:/config.json \
            getmeili/docs-scraper:latest pipenv run ./docs_scraper /config.json

          # 6. 關閉伺服器
          kill $SERVE_PID

      - name: Upload Build Artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: build

  deploy:
    name: Deploy to GitHub Pages
    needs: build

    # Grant GITHUB_TOKEN the permissions required to make a Pages deployment
    permissions:
      pages: write # to deploy to Pages
      id-token: write # to verify the deployment originates from an appropriate source

    # Deploy to the github-pages environment
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    runs-on: ubuntu-latest
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
